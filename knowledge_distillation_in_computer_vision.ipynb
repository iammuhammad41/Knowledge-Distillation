{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iammuhammad41/Knowledge-Distillation/blob/main/knowledge_distillation_in_computer_vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%capture\n",
        "# ! pip install super_gradients\n",
        "# !pip install diffusers --upgrade\n",
        "# !pip install invisible_watermark transformers accelerate safetensors"
      ],
      "metadata": {
        "id": "acvsncGQaLok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import time\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "from diffusers import StableDiffusionPipeline\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "import time\n"
      ],
      "metadata": {
        "id": "4svsOVvJlZxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from super_gradients.training import Trainer, models, dataloaders\n",
        "from super_gradients.training.metrics import Accuracy, Top5\n",
        "from torchvision import transforms\n",
        "\n",
        "CRASH_HANDLER=False\n",
        "\n",
        "trainer = Trainer(\n",
        "    experiment_name=\"beit_tester\",\n",
        "    ckpt_root_dir=\"content/checkpoints\"\n",
        "    )\n",
        "\n",
        "test_dataloader = dataloaders.get(\n",
        "    \"cifar10_val\",\n",
        "    dataloader_params={\"batch_size\": 64},\n",
        "    dataset_params={\"transforms\": [transforms.ToTensor(), transforms.Resize(224, antialias=True)]}\n",
        "    )\n",
        "\n",
        "pretrained_beit = models.get('beit_base_patch16_224',\n",
        "                             num_classes= 10,\n",
        "                             arch_params={\"image_size\": [224, 224], \"patch_size\": [16, 16]},\n",
        "                             pretrained_weights=\"cifar10\"\n",
        "                             )\n",
        "\n",
        "metrics = trainer.test(model=pretrained_beit,\n",
        "                       test_loader=test_dataloader,\n",
        "                       test_metrics_list=[Accuracy(), Top5()]\n",
        "                       )"
      ],
      "metadata": {
        "id": "eti4Psdu1KXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics"
      ],
      "metadata": {
        "id": "GSVLvDuCgA7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from super_gradients.training import KDTrainer\n",
        "\n",
        "experiment_name = \"my_first_kd_run\"\n",
        "\n",
        "checkpoint_dir = \"kd_checkpoints\"\n",
        "\n",
        "kd_trainer = KDTrainer(experiment_name=experiment_name, ckpt_root_dir=checkpoint_dir)"
      ],
      "metadata": {
        "id": "oem_xAREECGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from super_gradients.training import dataloaders, models\n",
        "\n",
        "train_dataloader = dataloaders.get(\"cifar10_train\",\n",
        "                                   dataloader_params={\"batch_size\": 128}\n",
        "                                   )\n",
        "\n",
        "val_dataloader = dataloaders.get(\"cifar10_val\",\n",
        "                                 dataloader_params={\"batch_size\": 512}\n",
        "                                 )\n",
        "\n",
        "student_resnet18 = models.get('resnet18_cifar', num_classes=10)"
      ],
      "metadata": {
        "id": "tq7K4TZ4EhSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def show(images, labels, classes, rows=6, columns=5):\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "\n",
        "  for i in range(1, columns * rows + 1):\n",
        "      fig.add_subplot(rows, columns, i)\n",
        "      plt.imshow(images[i-1].permute(1, 2, 0).clamp(0, 1))\n",
        "      plt.xticks([])\n",
        "      plt.yticks([])\n",
        "      plt.title(f\"{classes[labels[i-1]]}\")"
      ],
      "metadata": {
        "id": "0B0SxMRMMW5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vis_images_train, vis_labels_train = next(iter(train_dataloader))\n",
        "show(vis_images_train, vis_labels_train, classes=train_dataloader.dataset.classes)\n",
        "\n",
        "print(vis_images_train.shape, vis_labels_train.shape)"
      ],
      "metadata": {
        "id": "3fINIIgaMZ5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from super_gradients.training import training_hyperparams\n",
        "from super_gradients.training.losses import KDLogitsLoss, LabelSmoothingCrossEntropyLoss\n",
        "\n",
        "kd_params = {\n",
        "    \"max_epochs\": 10,\n",
        "    'lr_cooldown_epochs': 0,  # We dont want to use lr cooldown since we only train for 3 epochs\n",
        "    'lr_warmup_epochs': 0,    # We dont want to use lr  warmup  since we only train for 3 epochs\n",
        "    \"loss\": KDLogitsLoss(distillation_loss_coeff=0.8, task_loss_fn=LabelSmoothingCrossEntropyLoss()),\n",
        "    \"loss_logging_items_names\": [\"Loss\", \"Task Loss\", \"Distillation Loss\"]}\n",
        "\n",
        "training_params = training_hyperparams.get(\"imagenet_resnet50_kd\",\n",
        "                                           overriding_params=kd_params)"
      ],
      "metadata": {
        "id": "3PUfUEF7OcOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "\n",
        "pprint(training_params)"
      ],
      "metadata": {
        "id": "NEuSsxtgiFGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arch_params={\"teacher_input_adapter\": transforms.Resize(224)}"
      ],
      "metadata": {
        "id": "kyCFuxm0igZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kd_trainer.train(training_params = training_params,\n",
        "                 student = student_resnet18,\n",
        "                 teacher = pretrained_beit,\n",
        "                 kd_architecture = \"kd_module\",\n",
        "                 kd_arch_params = arch_params,\n",
        "                 train_loader = train_dataloader,\n",
        "                 valid_loader = val_dataloader\n",
        "                 )"
      ],
      "metadata": {
        "id": "hRaNRuVRM8kx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from super_gradients.training.metrics import Accuracy, Top5\n",
        "\n",
        "metrics = trainer.test(model=student_resnet18, test_loader=val_dataloader, test_metrics_list=[Accuracy(), Top5()])\n",
        "print()\n",
        "print(f\"Accuracy: {metrics['Accuracy']:.3f}\")\n",
        "print(f\"Top 5:    {metrics['Top5']:.3f}\")"
      ],
      "metadata": {
        "id": "E7-nj0AfsZjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "deci_diffusion_pipeline = StableDiffusionPipeline.from_pretrained('Deci/DeciDiffusion-v1-0',\n",
        "                                                   custom_pipeline='Deci/DeciDiffusion-v1-0',\n",
        "                                                   torch_dtype=torch.float16\n",
        "                                                   )\n",
        "\n",
        "deci_diffusion_pipeline.unet = deci_diffusion_pipeline.unet.from_pretrained('Deci/DeciDiffusion-v1-0',\n",
        "                                              subfolder='flexible_unet',\n",
        "                                              torch_dtype=torch.float16)\n",
        "\n",
        "# Move pipeline to device\n",
        "deci_diffusion_pipeline = deci_diffusion_pipeline.to('cuda')\n",
        "\n",
        "def text_to_image(pipeline, prompt):\n",
        "\n",
        "    # Start the timer\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Call the pipeline function directly\n",
        "    result = pipeline([prompt], generator=torch.Generator(\"cuda\").manual_seed(42))\n",
        "\n",
        "    # Calculate and print the elapsed time\n",
        "    elapsed_time = time.time() - start_time\n",
        "    display(HTML(f'<span style=\"color: #3264ff; font-weight:bold;font-size: 20px;\">Time taken to generate: {elapsed_time:.2f} seconds</span>'))\n",
        "\n",
        "    img = result.images[0]\n",
        "\n",
        "    filename = prompt.replace(' ', '_')\n",
        "    if len(filename) > 100:  # Limit filename to 100 characters\n",
        "        filename = filename[:100]\n",
        "\n",
        "    # Incorporate the pipeline's class name into the filename\n",
        "    pipeline_name = pipeline.__class__.__name__\n",
        "    save_path = os.path.join(\"/content\", f\"{filename}.png\")\n",
        "    img.save(save_path)\n",
        "\n",
        "    # Display the saved image\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    return save_path"
      ],
      "metadata": {
        "id": "CrWdS-kQlPQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cifar_classes = train_dataloader.dataset.classes\n",
        "\n",
        "for classes in cifar_classes:\n",
        "    text_to_image(deci_diffusion_pipeline, classes)"
      ],
      "metadata": {
        "id": "7x2Qd2VpsqTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import requests\n",
        "import torch\n",
        "\n",
        "trained_model = models.get('resnet18_cifar',\n",
        "                           checkpoint_path=f\"{checkpoint_dir}/{kd_trainer.experiment_name}/ckpt_best.pth\",\n",
        "                           num_classes= 10)"
      ],
      "metadata": {
        "id": "faYdygRys_b9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_and_display(path, model=trained_model, class_list=cifar_classes, device='cuda'):\n",
        "    \"\"\"\n",
        "    Load image from the specified path, preprocess it, predict its class using the given model,\n",
        "    and then display the image with its predicted class as the label.\n",
        "\n",
        "    Args:\n",
        "    - path (str): Path to the image file.\n",
        "    - model (torch.nn.Module): The trained model for prediction.\n",
        "    - class_list (list): List of classes.\n",
        "    - device (str): Device for running the model. Default is 'cuda'.\n",
        "\n",
        "    Returns:\n",
        "    - None. Displays the image with the predicted class label.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load and convert the image to numpy array\n",
        "    image = np.asarray(Image.open(path))\n",
        "\n",
        "    # Define the transformations\n",
        "    pred_transforms = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize((32, 32)),\n",
        "        transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))\n",
        "    ])\n",
        "\n",
        "    # Ensure the model is in evaluation mode and on the specified device\n",
        "    model = model.eval().to(device)\n",
        "\n",
        "    # Make a prediction\n",
        "    predictions = model(pred_transforms(image).unsqueeze(0).to(device))\n",
        "\n",
        "    # Display the image with the predicted class as the label\n",
        "    plt.xlabel(class_list[torch.argmax(predictions)])\n",
        "    plt.imshow(image)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Duiy4ivDut6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_and_display(\"/content/DeciDiffusionPipeline_ship.png\")"
      ],
      "metadata": {
        "id": "EIj7pr2UxGyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_and_display(\"/content/DeciDiffusionPipeline_frog.png\")"
      ],
      "metadata": {
        "id": "OIWDxydexG6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_and_display(\"/content/DeciDiffusionPipeline_airplane.png\")"
      ],
      "metadata": {
        "id": "RnaCU1lDxHDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_and_display(\"/content/DeciDiffusionPipeline_bird.png\")"
      ],
      "metadata": {
        "id": "ZOeMDGP9xHKC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}